{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7d22e9c3",
      "metadata": {
        "id": "7d22e9c3"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "random.seed(1)\n",
        "np.random.seed(1)\n",
        "tf.random.set_seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5a99fefd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a99fefd",
        "outputId": "c515605a-e29b-46dc-b983-6a4ff2582655"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "(25000,)\n",
            "(25000,)\n",
            "(25000,)\n",
            "(25000,)\n",
            "[1, 591, 202, 14, 31, 6, 717, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 2, 38, 32, 25, 7944, 451, 202, 14, 6, 717]\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# load the dataset but only keep the top n words, zero the rest\n",
        "# 단어의 등장 빈도 순위 , 여기서는 10000 이므로 1~10000 순위의 총 10000개 단어 사용\n",
        "# 빈도 횟수가 제일 많은 10000개의 단어를 학습에 이용하게 됩니다. (문장의 갯수 = 총 review의 갯수화 혼동하시면 안됩니다.)\n",
        "\n",
        "top_words = 10000\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=top_words) #데이터로드에 정해진 parameter로서, 할당된 크기만큼 자주쓰인 단어를 불러옴\n",
        "\n",
        "print(x_train.shape) # list가 총 25,000개 있음, 이 리뷰안에 여러 단어가 쓰였을텐데 위에서 언급한 10000개의 단어만 사용하게 됩니다.\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)  # 0과 1이 있다. 0의 경우 부정 , 1의 경우 긍정\n",
        "print(x_test[0])\n",
        "print(y_test[0]) #0 이 나온 것으로 미루어 부정적인 리뷰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "89c42f1f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "89c42f1f",
        "outputId": "4163bb01-755e-48eb-b5ff-82499b62c910"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "<class 'dict'>\n",
            "88584\n",
            "the\n",
            "and\n",
            "a\n",
            "of\n",
            "to\n",
            "direct\n",
            "[Example] lengths of 5 reviews:  [218, 189, 141, 550, 147]\n",
            "The longest length of the review : 2494\n",
            "The average length of the review : 238.71364\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#data구조를 좀더 알아 보겠습니다.\n",
        "word_to_index = tf.keras.datasets.imdb.get_word_index()\n",
        "print(type(word_to_index))\n",
        "# print(word_to_index) ## word_to_index는 dic 이며, 위 쪽 print 해보면 좀더 자세하게d dict구조를 알 수 있습니다. #key는 단어, #value는 그 단어의 빈도수 순위입니다.\n",
        "print(len(word_to_index.items()))\n",
        "\n",
        "#제일 많이 사용된 단어 몇개를 살펴보겠습니다. 먼저 key와 value를 바꾸겠습니다.\n",
        "index_to_word ={}\n",
        "for key, value in word_to_index.items():  ## dictionary 를 tuple들로 만들기\n",
        "    index_to_word[value + 3] = key ## value+3가 단어가 사용된 순위, key가 단어입니다. +3을 해주는 이유는 0,1,2가 special로 설정되었기 때문에, 3이 제일 많이 나온 단어이기 때문입니다.\n",
        "\n",
        "for i in range(5) :\n",
        "    print(index_to_word[i + 4])  ## 제일 많이 나온 단어 5개  / 다섯번째를 불러오는게 아니라 키 값에 맞는 value를 불러오는 것임.\n",
        "\n",
        "print(index_to_word[1504]) ## 1500번째로 잘 많이 나온 단어\n",
        "\n",
        "#한 문장(한 데이터가)의 길이가 어느정도 되는지 알아보겠습니다.\n",
        "len_result = [len(s) for s in x_train] #길이의 값을 list로 만듦\n",
        "print('[Example] lengths of 5 reviews: ', len_result[:5])\n",
        "print('The longest length of the review : {}'.format(np.max(len_result)))\n",
        "print('The average length of the review : {}'.format(np.mean(len_result)))\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.hist(len_result, bins=50)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0f56b0df",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f56b0df",
        "outputId": "0eaf6948-feba-4df9-9c63-0ce8900256b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]\n",
            "<sos> this has to be one of the worst films of the 1990s when my friends i were watching this film being the target audience it was aimed at we just sat watched the first half an hour with our jaws touching the floor at how bad it really was the rest of the time everyone else in the theatre just started talking to each other leaving or generally crying into their popcorn that they actually paid money they had <unk> working to watch this feeble excuse for a film it must have looked like a great idea on paper but on film it looks like no one in the film has a clue what is going on crap acting crap costumes i can't get across how <unk> this is to watch save yourself an hour a bit of your life\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "#구체적인 문장을 가져와보겠습니다.\n",
        "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")): #pad 패드토큰=단어 #sos 시작을 알리는 토큰 #unk 주어진 단어가 미확인이라고 하는 토큰 (이것은 데이터를 만드는 사람이 사전 작업을 통해 셋팅한 것입니다.)\n",
        "    index_to_word[index]=token\n",
        "print(x_train[2])\n",
        "print(' '.join([index_to_word[index] for index in x_train[2]]))  #하나하나 element를 쭉 연결 시킨 것 어떤 문장인지 글로 확인해보기\n",
        "print(y_train[2]) #어떤 리뷰인지 맞춰보기 0은 부정 1은 긍정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2b55074d",
      "metadata": {
        "id": "2b55074d"
      },
      "outputs": [],
      "source": [
        "# truncate and pad input sequences with .preprocessing.sequence.pad_sequences\n",
        "# rnn에서 Input값의 길이 기본 rnn 에서는 Sequence의 길이가 같아야 하기 때문에 아래의 작업을 필요로 합니다.\n",
        "max_len = 200  # 이 길이보다 sequence의 길이가 자르면 잘라낼 것이고, 짧다면 의미없는 값을 집어넣어 sequence의 길이를 200으로 맞추어 줍니다.\n",
        "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen = 200)# 이 과정이 없으면 길이가 다른 문제가 생깁니다. 이것은 길이를 최대 200으로 맞춰주는 역할을 합니다.\n",
        "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen= 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "318d3aa5",
      "metadata": {
        "id": "318d3aa5"
      },
      "outputs": [],
      "source": [
        "#tf.keras.callbacks 의 EarlyStopping / ModelCheckpoint\n",
        "#keras를 활용해 early stopping을 사용하겠습니다. monitor : 관찰하는 값. mode는 기본은 auto 이곳에선 loss기 때문에 min을 사용하였습니다. patience =3 입니다.\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
        "# 모델을 저장하는 방법입니다. ./rnn_imdb란 저장되는 경로를 말하며, 제일 좋은 값으로만 저장하였고, 그 기준은 val_accuracy가 max일 때 입니다.\n",
        "mc = tf.keras.callbacks.ModelCheckpoint('./best_model.keras', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c441a82c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "c441a82c",
        "outputId": "47a7d996-8b01-4618-9f0c-1d930f75e9d5",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "rnn = tf.keras.Sequential()\n",
        "rnn.add(layers.Embedding(top_words, 160)) # 100000 * 160 ,10000개의 단어가 160차원의 벡터로 임베딩 https://keras.io/ko/layers/embeddings/ This layer can only be used as the first layer in a model.\n",
        "#output (배치의크기, sequence의 길이, 한 단어의 길이)\n",
        "rnn.add(layers.SimpleRNN(64)) #Whh = 64*64 , Wxh = 64*160, b =64\n",
        "rnn.add(layers.Dense(1, activation ='sigmoid'))# 앞의 64개에 대한 weight 64+ bias: 1\n",
        "rnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5a2cfcc8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a2cfcc8",
        "outputId": "fc8a5515-c96d-4e1c-a57f-f55aa8f33238"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5723 - loss: 0.6706\n",
            "Epoch 1: val_accuracy improved from -inf to 0.67140, saving model to ./best_model.keras\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 94ms/step - accuracy: 0.5725 - loss: 0.6705 - val_accuracy: 0.6714 - val_loss: 0.5982\n",
            "Epoch 2/5\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7763 - loss: 0.4737\n",
            "Epoch 2: val_accuracy did not improve from 0.67140\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 89ms/step - accuracy: 0.7763 - loss: 0.4737 - val_accuracy: 0.6578 - val_loss: 0.6571\n",
            "Epoch 3/5\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.8015 - loss: 0.4349\n",
            "Epoch 3: val_accuracy did not improve from 0.67140\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 90ms/step - accuracy: 0.8015 - loss: 0.4350 - val_accuracy: 0.6612 - val_loss: 0.6242\n",
            "Epoch 4/5\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.8158 - loss: 0.4169\n",
            "Epoch 4: val_accuracy improved from 0.67140 to 0.67640, saving model to ./best_model.keras\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 86ms/step - accuracy: 0.8158 - loss: 0.4169 - val_accuracy: 0.6764 - val_loss: 0.6358\n",
            "Epoch 4: early stopping\n"
          ]
        }
      ],
      "source": [
        "rnn.compile(optimizer='adam', loss = 'binary_crossentropy', metrics =['accuracy'])\n",
        "#callbacks의 기능은 위에서 정의한 early stopping 과 model_check_point를 저장한다는 의미 입니다.\n",
        "result = rnn.fit(x_train, y_train, epochs =5, callbacks=[es,mc], batch_size=60, validation_split =0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "fe5f85c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe5f85c4",
        "outputId": "f5f07857-ef04-4bdc-9052-6fd42906b5bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.6748 - loss: 0.6466\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6447280645370483, 0.6740400195121765]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "rnn.evaluate(x_test,y_test) #위의 결과 보면 overfitting을 서서히 생각해봐야함"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "8798307a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8798307a",
        "outputId": "c2fa2860-996f-4859-a657-ac37b0ad7278"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.6748 - loss: 0.6466\n",
            "[0.6447280645370483, 0.6740400195121765]\n"
          ]
        }
      ],
      "source": [
        "loaded_model = tf.keras.models.load_model('best_model.keras')   ###위의 결과값과 아래의 결과값이 다른 이유는 학습된 모델에 저장된 weight가 다르기 때문입니다. 저장하는 모델에는 early stopping과 check point가 적용되기 때문입니다.\n",
        "print((loaded_model.evaluate(x_test, y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f35dded5",
      "metadata": {
        "id": "f35dded5"
      },
      "outputs": [],
      "source": [
        "def sentiment_predict(new_sentence):\n",
        "    # 알파벳과 숫자를 제외하고 모두 제거 및 알파벳 소문자화\n",
        "    new_sentence = re.sub('[^0-9a-zA-Z ]', '', new_sentence).lower()\n",
        "\n",
        "    # 정수 인코딩\n",
        "    encoded = []\n",
        "    for word in new_sentence.split():\n",
        "        # 단어 집합의 크기를 10,000으로 제한.\n",
        "        try :\n",
        "            if word_to_index[word] <= 10000:\n",
        "                encoded.append(word_to_index[word]+3)\n",
        "            else:\n",
        "                # 10,000 이상의 숫자는 <unk> 토큰으로 취급.\n",
        "                encoded.append(2)\n",
        "        # 단어 집합에 없는 단어는 <unk> 토큰으로 취급.\n",
        "        except KeyError:\n",
        "            encoded.append(2)\n",
        "\n",
        "    pad_new = tf.keras.preprocessing.sequence.pad_sequences([encoded], maxlen = max_len) # 패딩\n",
        "    score = float(loaded_model.predict(pad_new)) # 예측\n",
        "    if(score > 0.5):\n",
        "        print(\"positive with the probability {:.2f}% .\".format(score * 100))\n",
        "    else:\n",
        "        print(\"negative with the probability {:.2f}% \".format((1 - score) * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b81d41c6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b81d41c6",
        "outputId": "6ce1b521-cf41-473b-fc24-963ef22ae1c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step\n",
            "positive with the probability 75.35% .\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "negative with the probability 71.95% \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-0be091181bb0>:20: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  score = float(loaded_model.predict(pad_new)) # 예측\n"
          ]
        }
      ],
      "source": [
        "#편하게 문장을 치시고 리뷰의 정확성을 비교해보세요.\n",
        "My_review_1 = \"hi this movie is the amazing movie I have ever seen in my life. really intersting very fun.\"\n",
        "sentiment_predict(My_review_1)\n",
        "My_review_2 = \"The final scene at the movie was disgusting\"\n",
        "sentiment_predict(My_review_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c79d2065",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "c79d2065",
        "outputId": "86b2352b-0afd-49de-ebf4-6bf42b8b8457"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "lstm = tf.keras.Sequential()\n",
        "lstm.add(layers.Embedding(top_words, 160)) # 차이점 확인  10,000 * 160\n",
        "lstm.add(layers.LSTM(64))  # activation = tanh 기본\n",
        "lstm.add(layers.Dense(2, activation ='softmax'))  # 2 = num_classes, #softmax 마지막에 했으므로 logit 이 들어간 loss를 사용하지 않습니다.\n",
        "lstm.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c9e6c864",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9e6c864",
        "outputId": "b8b61968-f69e-4673-c9e3-383104255c11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train LSTM Model With \n",
            "Epoch 1/5\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.7079 - loss: 0.5503\n",
            "Epoch 1: val_accuracy improved from 0.67640 to 0.86240, saving model to ./best_model.keras\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 248ms/step - accuracy: 0.7081 - loss: 0.5500 - val_accuracy: 0.8624 - val_loss: 0.3407\n",
            "Epoch 2/5\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.8870 - loss: 0.2857\n",
            "Epoch 2: val_accuracy improved from 0.86240 to 0.86820, saving model to ./best_model.keras\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 244ms/step - accuracy: 0.8870 - loss: 0.2856 - val_accuracy: 0.8682 - val_loss: 0.3124\n",
            "Epoch 3/5\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.9160 - loss: 0.2168\n",
            "Epoch 3: val_accuracy improved from 0.86820 to 0.87140, saving model to ./best_model.keras\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 244ms/step - accuracy: 0.9160 - loss: 0.2168 - val_accuracy: 0.8714 - val_loss: 0.3592\n",
            "Epoch 4/5\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 0.9377 - loss: 0.1653\n",
            "Epoch 4: val_accuracy did not improve from 0.87140\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 260ms/step - accuracy: 0.9377 - loss: 0.1653 - val_accuracy: 0.8626 - val_loss: 0.4540\n",
            "Epoch 5/5\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.9537 - loss: 0.1319\n",
            "Epoch 5: val_accuracy did not improve from 0.87140\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 242ms/step - accuracy: 0.9536 - loss: 0.1319 - val_accuracy: 0.8486 - val_loss: 0.4197\n",
            "Epoch 5: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c4388162e10>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "lstm.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', metrics =['accuracy'])\n",
        "print(\"Train LSTM Model With \")\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, random_state = 1, stratify = y_train)\n",
        "\n",
        "#lstm = rnn.fit(x_train, y_train, epochs =10, callbacks=[mc2], batch_size=60, validation_split =0.2)\n",
        "#궁금한 것 위에 Fit 에서 split = 0.2 하면 랜덤이 아니라 일정하게 쪼개지 않음. 뒤의 20% 가져옴. 따라서 반복에 좋지 않습니다.\n",
        "\n",
        "lstm.fit(x_train, y_train, epochs=5, callbacks = [es,mc], batch_size= 60, validation_data=(x_val, y_val) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "0f637288",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f637288",
        "outputId": "e1ee7649-9a52-4c05-d8ed-f9774086abbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 32ms/step - accuracy: 0.8363 - loss: 0.4502\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4388419985771179, 0.8396000266075134]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "lstm.evaluate(x_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "7d811269",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d811269",
        "outputId": "40fff64d-8353-4406-d4c8-f990f529095f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 32ms/step - accuracy: 0.8615 - loss: 0.3790\n",
            "[0.3772801160812378, 0.8604400157928467]\n"
          ]
        }
      ],
      "source": [
        "loaded_model2 = tf.keras.models.load_model('best_model.keras')\n",
        "print((loaded_model2.evaluate(x_test, y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "5a236484",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a236484",
        "outputId": "3e605910-9b48-4775-d2fb-8c591e29fc3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Multi_LSTM\n",
            "Epoch 1/5\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - accuracy: 0.7015 - loss: 0.5415\n",
            "Epoch 1: val_accuracy improved from 0.87140 to 0.87300, saving model to ./best_model.keras\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 361ms/step - accuracy: 0.7017 - loss: 0.5411 - val_accuracy: 0.8730 - val_loss: 0.2989\n",
            "Epoch 2/5\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step - accuracy: 0.8901 - loss: 0.2687\n",
            "Epoch 2: val_accuracy did not improve from 0.87300\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 370ms/step - accuracy: 0.8901 - loss: 0.2687 - val_accuracy: 0.8718 - val_loss: 0.3075\n",
            "Epoch 3/5\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step - accuracy: 0.9253 - loss: 0.1971\n",
            "Epoch 3: val_accuracy did not improve from 0.87300\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 369ms/step - accuracy: 0.9252 - loss: 0.1972 - val_accuracy: 0.8684 - val_loss: 0.3678\n",
            "Epoch 4/5\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step - accuracy: 0.9398 - loss: 0.1603\n",
            "Epoch 4: val_accuracy did not improve from 0.87300\n",
            "\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 371ms/step - accuracy: 0.9398 - loss: 0.1603 - val_accuracy: 0.8524 - val_loss: 0.4963\n",
            "Epoch 4: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c438810b010>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "multi_lstm = tf.keras.Sequential()\n",
        "multi_lstm.add(layers.Embedding(top_words, 160))\n",
        "multi_lstm.add(layers.LSTM(64, return_sequences = True)) ## return sequence는 매번 hideen cell 에서 ouput을 내보내고, 이것이 다음 layer의 input값으로 사용됩니다.\n",
        "multi_lstm.add(layers.LSTM(64))\n",
        "multi_lstm.add(layers.Dense(2, activation ='softmax'))\n",
        "\n",
        "multi_lstm.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', metrics =['accuracy'])\n",
        "print(\"Train Multi_LSTM\")\n",
        "multi_lstm.fit(x_train, y_train, epochs = 5, callbacks = [es,mc], batch_size= 60, validation_data=(x_val, y_val) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "83120124",
      "metadata": {
        "id": "83120124",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70986579-1209-4534-ba72-480e717ff339"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 57ms/step - accuracy: 0.8662 - loss: 0.3196\n",
            "[0.323954701423645, 0.8655200004577637]\n"
          ]
        }
      ],
      "source": [
        "loaded_model = tf.keras.models.load_model('best_model.keras')\n",
        "print((loaded_model.evaluate(x_test, y_test)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}