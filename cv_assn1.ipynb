{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment1: PyTorch Classification\n",
    "* Cifar10 dataset에 대해 정확도 97% 이상의 Classifier를 만드세요\n",
    "* 코드 수정 가능 (단, 첫 번째 cell은 건드리지 말 것)\n",
    "* Hint. 모델 디자인 뿐만 아니라 transfer learning, batch size 및 learning rates 조절, data augmentation 등을 통해 분류기 정확도를 높일 수 있음. (https://pytorch.org/vision/stable/transforms.html)\n",
    "* 단, transfer learning 사용 시, cifar10에 학습된 모델을 사용하는 것은 금지함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 아래 코드는 Shallow CNN을 사용한 예시 코드입니다.\n",
    "* 바로 아래 위치한 셀은 수정하시면 안됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Do not touch codes below!\n",
    "# These codes control random seed for reproduction\n",
    "seed = 7777\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset CIFAR10 download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = './CIFAR10'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cifar10_train = datasets.CIFAR10(\n",
    "    img_dir, download=True, transform = ToTensor(), train=True)\n",
    "\n",
    "cifar10_test = datasets.CIFAR10(\n",
    "    img_dir, download=True, transform = ToTensor(), train=False)\n",
    "\n",
    "dataloader_train = DataLoader(cifar10_train, \n",
    "                              batch_size=128, \n",
    "                              shuffle=True)\n",
    "\n",
    "dataloader_test = DataLoader(cifar10_test, \n",
    "                              batch_size=128, \n",
    "                              shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(10, 8))\n",
    "cols, rows = 5, 5\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(cifar10_train), size=(1,)).item()\n",
    "    img, label = cifar10_train[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(label)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.permute(1,2,0).squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic model using CNN\n",
    "##### structure\n",
    "- Convolution 1 : channels 16, kernel size 5, stride 1, padding 2 (output resolution?)\n",
    "- ReLU\n",
    "- MaxPool : kernel_size 2, stride 2\n",
    "- Convlution 2 : channels 32, kernel size 5, stride 1, padding 2 (output resolution?)\n",
    "- Linear : output channels 10 \n",
    "\n",
    "##### This model below is just for an example\n",
    "\n",
    "##### https://pytorch.org/docs/1.12/nn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=3,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "                padding=2,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2),    \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Linear(32 * 8 * 8, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)       \n",
    "        output = self.out(x)\n",
    "        return output  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "cnn = CNN().to(device)\n",
    "loss_func = nn.CrossEntropyLoss()   \n",
    "optimizer = optim.SGD(cnn.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "\n",
    "model_best = None\n",
    "acc_best = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    cnn.train()\n",
    "    for i, (images, labels) in enumerate(dataloader_train):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        output = cnn(images)     \n",
    "        _, preds = torch.max(output, 1)     \n",
    "        loss = loss_func(output, labels)\n",
    "\n",
    "        # clear gradients for this training step   \n",
    "        optimizer.zero_grad()           \n",
    "\n",
    "        # backpropagation, compute gradients \n",
    "        loss.backward()    \n",
    "        # apply gradients             \n",
    "        optimizer.step()        \n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "    \n",
    "    epoch_loss = running_loss / len(cifar10_train)\n",
    "    epoch_acc = running_corrects.double() / len(cifar10_train)\n",
    "    print ('Epoch [{}/{}], Train -> Loss: {:.4f}, Acc: {:.4f}' \n",
    "                   .format(epoch + 1, num_epochs, epoch_loss, epoch_acc))\n",
    "        \n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    cnn.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(dataloader_test):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Inference\n",
    "            output = cnn(images)\n",
    "            _, preds = torch.max(output, 1)     \n",
    "    \n",
    "            # Calculate loss\n",
    "            loss = loss_func(output, labels)\n",
    "    \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    # 통계값\n",
    "    epoch_loss = running_loss / len(cifar10_test)\n",
    "    epoch_acc = running_corrects.double() / len(cifar10_test)\n",
    "\n",
    "    print ('Epoch [{}/{}], Valid -> Loss: {:.4f}, Acc: {:.4f}' \n",
    "               .format(epoch + 1, num_epochs, epoch_loss, epoch_acc))\n",
    "\n",
    "    # Fine the best model\n",
    "    if acc_best < epoch_acc:\n",
    "        acc_best = epoch_acc\n",
    "        model_best = copy.deepcopy(cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_best.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in dataloader_test:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Inference\n",
    "        test_output = model_best(images)\n",
    "\n",
    "        # Calculate error\n",
    "        pred_y = torch.max(test_output, 1)[1].data.squeeze() # max 를 통해 가장 확률이 높은 숫자를 선택\n",
    "        correct += (pred_y == labels).sum().item() # 가장 확률이 높은 숫자인 pred_y와 label이 같으면 정답 - 정답인 개수 확인\n",
    "        total += labels.size(0) \n",
    "    accuracy = correct / total * 100\n",
    "    \n",
    "print('Test Accuracy of the model on the 10000 test images: %.2f Percent' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_best.state_dict(), 'trained_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the trained model and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load = CNN().to(device)\n",
    "model_load.load_state_dict(torch.load('trained_model.pkl'))\n",
    "\n",
    "model_load.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in dataloader_test:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Inference\n",
    "        test_output = model_load(images)\n",
    "\n",
    "        # Calculate error\n",
    "        pred_y = torch.max(test_output, 1)[1].data.squeeze() # max 를 통해 가장 확률이 높은 숫자를 선택\n",
    "        correct += (pred_y == labels).sum().item() # 가장 확률이 높은 숫자인 pred_y와 label이 같으면 정답 - 정답인 개수 확인\n",
    "        total += labels.size(0) \n",
    "    accuracy = correct / total * 100\n",
    "    \n",
    "print('Test Accuracy of the model on the 10000 test images: %.2f Percent' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try your own codes!\n",
    "* 과제로 제출한 checkpoint를 'torch.load' 및 'torch.load_state_dict'를 사용해 불러온 후, accuracy를 측정할 예정입니다.\n",
    "* 위의 Save 및 Load 코드를 기반으로 여러분이 직접 학습한 모델의 checkpoint가 잘 동작하는지 확인하시기 바랍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
