{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "slkFycYCJWey"
   },
   "source": [
    "# 28기 AI/Bigdata 아카데미 자연어처리 과목의 실습을 위한 견본 코드입니다.\n",
    "본 코드는 주어진 한국어 hate-speech 데이터셋을 text classification task로 학습 및 추론을 수행합니다.\n",
    "\n",
    "본 프로젝트에 참여하신 여러분은 코드를 수정하여 성능을 향상시키시면 됩니다.\n",
    "\n",
    "코드 수정의 예시로는\n",
    "*   하이퍼 패러미터 조정\n",
    "*   전처리 과정 추가 혹은 변경 (이를테면 기사 제목 또한 학습에 사용)\n",
    "*   토큰화 방법 조정\n",
    "\n",
    "들이 있고, 이에 국한되지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jb0uDWETL5bY"
   },
   "source": [
    "먼저 모델과 데이터셋을 로드하고 학습하는데 필요한 패키지를 설치합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 103145,
     "status": "ok",
     "timestamp": 1745295465982,
     "user": {
      "displayName": "김대희andrea0119",
      "userId": "12438135036756140833"
     },
     "user_tz": -540
    },
    "id": "ymhxqWzlIVd1",
    "outputId": "19c77da6-b661-45cf-fe39-65add265163e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (3.1.0)\n",
      "Requirement already satisfied: transformers in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (4.46.3)\n",
      "Requirement already satisfied: accelerate in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (1.0.1)\n",
      "Requirement already satisfied: evaluate in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (0.4.3)\n",
      "Requirement already satisfied: filelock in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from datasets) (1.24.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from datasets) (3.10.11)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from datasets) (0.30.2)\n",
      "Requirement already satisfied: packaging in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: psutil in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from accelerate) (2.4.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from aiohttp->datasets) (1.15.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from huggingface-hub>=0.23.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: sympy in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./anaconda3/envs/imageprocessing/lib/python3.8/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install datasets transformers accelerate evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJxLmLdXMMws"
   },
   "source": [
    "설치후 패키지를 로드해주고, 재현성을 위해 시드를 고정해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 38
    },
    "executionInfo": {
     "elapsed": 5546,
     "status": "ok",
     "timestamp": 1745295479679,
     "user": {
      "displayName": "김대희andrea0119",
      "userId": "12438135036756140833"
     },
     "user_tz": -540
    },
    "id": "WZmCX9a0-iz-",
    "outputId": "bebd6e0b-7085-47ba-a139-319e34751d6a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dummy/dummy/runs/wbqcclko?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fa41704e460>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(mode=\"disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 13735,
     "status": "ok",
     "timestamp": 1745295495623,
     "user": {
      "displayName": "김대희andrea0119",
      "userId": "12438135036756140833"
     },
     "user_tz": -540
    },
    "id": "nkHxoUSiJqSn"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "from datasets import load_dataset\n",
    "\n",
    "transformers.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wmLDPwWyMPaH"
   },
   "source": [
    "## 데이터 로드\n",
    "\n",
    "이제 데이터셋을 로드해줍니다. \\\n",
    "kaggle에서 본 코드를 실행하신 경우, 데이터셋이 자동으로 런타임 루트 경로의 `kaggle/input`디렉토리에 마운트됩니다.\n",
    "\n",
    "밑의 코드로 마운트된 경로의 데이터를 읽어옵니다.\n",
    "\n",
    "만일 기사 제목을 추가적으로 학습에 사용하고 싶으시다면, \\\n",
    "같은 경로의 `train.news_title.txt`, `dev.news_title.txt`, `test.news_title.txt`도 추가적으로 로드후, \\\n",
    "Huggingface Datasets 패키지의 [`concatenate_datasets`](https://huggingface.co/docs/datasets/process#concatenate) 메서드를 활용하여 각 스플릿에 추가해주시면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "executionInfo": {
     "elapsed": 441,
     "status": "error",
     "timestamp": 1745295498930,
     "user": {
      "displayName": "김대희andrea0119",
      "userId": "12438135036756140833"
     },
     "user_tz": -540
    },
    "id": "euFCHnStNn7g",
    "outputId": "08b5d3f9-d78f-45ef-d75a-1dca376c6c18"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 7896 examples [00:00, 161158.46 examples/s]\n",
      "Generating train split: 471 examples [00:00, 42091.39 examples/s]\n",
      "Generating train split: 974 examples [00:00, 65273.17 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# TODO: colab 테스트 때문에 경로 바꿈. /content/input/korean-hate-speech-detection/ 경로를 나중에 /kaggle/input/korean-hate-speech-detection/ 으로 바꾸기\n",
    "train_dataset = load_dataset(\"csv\", data_files=\"train.hate.csv\")['train']\n",
    "dev_dataset = load_dataset(\"csv\", data_files=\"dev.hate.csv\")['train']\n",
    "test_dataset = load_dataset(\"csv\", data_files=\"test.hate.no_label.csv\")['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLX5-_xMVpb5"
   },
   "source": [
    "데이터셋의 구조를 확인해봅시다. 만일 추가한 것이 없을 경우, `train` 스플릿에서는 `comments`와 `label` column 만이 있을 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "NXOR5cZqVoVA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['comments', 'label'],\n",
       "    num_rows: 7896\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DW7yO-iCPuNd"
   },
   "source": [
    "이제 한국어 hate-speech 데이터셋의 3가지 split `train`, `dev`, `test`을 모두 로드했습니다.\n",
    "\n",
    "각 split에 대해 간단히 설명하자면, \\\n",
    "`train` split은 모델의 학습에 이용되어야 하고, \\\n",
    "`dev` split은 `train` split으로 학습한 모델의 hyper-parameter 조정 등을 위해 사용되어야 하고, \\\n",
    "`test` split은 튜닝이 완료된 최종 모델의 결과를 추론하는데 사용하는 데이터셋입니다.\n",
    "\n",
    "`test` split의 결과는 모델 튜닝 중 사용되서는 안되며, 따라서 **레이블도 제공되지 않습니다**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "vGWIi6wD-i0A"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'comments': '(현재 호텔주인 심정) 아18 난 마른하늘에 날벼락맞고 호텔망하게생겼는데 누군 계속 추모받네....',\n",
       " 'label': 'hate'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0] # 첫번쨰 데이터 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrxPevY4TrOF"
   },
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "roS5A59RT8ZS"
   },
   "source": [
    "이제 데이터셋을 전처리해줍니다.\n",
    "\n",
    "본 코드는 예시 코드이기때문에, 간단하게 토크나이징만 진행합니다.\n",
    "\n",
    "본 예시에서는 [`beomi/KcELECTRA-base`](https://huggingface.co/beomi/KcELECTRA-base)를 사용합니다. (모델 레포에 유용한 정보가 많이 있습니다.)\\\n",
    "만일 다른 모델을 사용하고 싶으시다면, [여기](https://huggingface.co/models?pipeline_tag=text-classification&language=ko)에서 다른 모델들을 해당 태스크에 적합한 다른 모델들을 찾아볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "86Feji47VIyB"
   },
   "outputs": [],
   "source": [
    "model_checkpoint = 'beomi/KcELECTRA-base'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6b1drOk9Vciv"
   },
   "source": [
    "해당 모델의 토크나이저를 로드해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "n4cuDGPoRg8m"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ycjcV98Vf2_"
   },
   "source": [
    "이제 전처리에 사용할 함수를 정의해줍니다. 각 데이터는 `examples`라는 패러미터로 전달됩니다.\n",
    "\n",
    "예시 전처리 함수는 토크나이징 및 `label` 데이터를 숫자로 매핑하는 처리만을 다룹니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "lf-6FWSkZlXG"
   },
   "outputs": [],
   "source": [
    "label2id = {\n",
    "    'none': 0,\n",
    "    'offensive': 1,\n",
    "    'hate': 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "9rJvFPDvVYu9"
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    result_dict = tokenizer(examples['comments'], truncation=True)\n",
    "    # 추가하고 싶은 전처리 과정이 있으시다면, 여기에 추가해주시면 됩니다.\n",
    "    # 만일 기사 제목 데이터를 추가하셨다면, 밑의 예시 코드를 활용하여 두 column이 합쳐진 토크나이징 결과를 얻을 수 있습니다.\n",
    "    # result_dict = tokenizer(examples[sentence1_key], examples[sentence2_key], truncation=True)\n",
    "    if 'label' in examples.keys():\n",
    "      result_dict['label'] = [label2id[label_str] for label_str in examples['label']]\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "0BcYL5ducKV-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████| 7896/7896 [00:00<00:00, 19980.93 examples/s]\n",
      "Map: 100%|███████████████████████████| 471/471 [00:00<00:00, 9927.67 examples/s]\n",
      "Map: 100%|███████████████████████████| 974/974 [00:00<00:00, 3506.00 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(preprocess_function, batched=True, remove_columns=['comments','label'])\n",
    "dev_dataset = dev_dataset.map(preprocess_function, batched=True, remove_columns=['comments','label'])\n",
    "test_dataset = test_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOd96y5cib1-"
   },
   "source": [
    "전처리 후, 데이터셋의 구조가 어떻게 바뀌었는지 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "rqe6v9TRikIJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 7896\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UywzUqumilFy"
   },
   "source": [
    "이제 `train` 스플릿 기준 `input_ids`, `attention_mask`, `token_type_ids`, `label` 네 가지 column이 생긴 것을 확인하실 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yy30rwF2c20g"
   },
   "source": [
    "## 모델 학습\n",
    "\n",
    "이제 선택한 모델을 학습해봅시다.\n",
    "이를 위해 우선 모델을 로드해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "1f5TdNzKdJbv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "num_labels = 3  # none, offensive, hate 세 가지 이므로\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z6nPA_JgdYD4"
   },
   "source": [
    "이제 학습에 사용할 하이퍼 패리미터를 정의합니다.\n",
    "하이퍼 패러미터를 조정하실 분은 밑의 코드를 변경하시면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Q1fXAXAodjqj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "batch_size = 16\n",
    "learning_rate = 2e-5\n",
    "epochs = 5\n",
    "weight_decay = 0.01\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-lr{learning_rate}-epochs{epochs}-decay{weight_decay}-hate\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=learning_rate,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=epochs,\n",
    "    weight_decay=weight_decay,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kk2Nf0ZxeYQv"
   },
   "source": [
    "이후 해당 하이퍼 패러미터를 비롯한 정보들을 Huggingface Trainer에 넘겨줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "6EamiXNM-i0B"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 4.20k/4.20k [00:00<00:00, 2.20MB/s]\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    logits, labels = p\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "svHFdgACeUOd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5211/3846473124.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=dev_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHCdQdVeezxp"
   },
   "source": [
    "이제 학습을 진행합니다. 기본 하이퍼 패리미터에서 `NVIDIA T4` GPU 기준 약 7~8분 정도 소요됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "CJ5qzy9oe3J4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piai/anaconda3/envs/imageprocessing/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1235' max='1235' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1235/1235 04:05, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.808116</td>\n",
       "      <td>0.630573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.720663</td>\n",
       "      <td>0.685775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.761000</td>\n",
       "      <td>0.779006</td>\n",
       "      <td>0.658174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.761000</td>\n",
       "      <td>0.950549</td>\n",
       "      <td>0.641189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.460900</td>\n",
       "      <td>0.900491</td>\n",
       "      <td>0.660297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piai/anaconda3/envs/imageprocessing/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/piai/anaconda3/envs/imageprocessing/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/piai/anaconda3/envs/imageprocessing/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/piai/anaconda3/envs/imageprocessing/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/piai/anaconda3/envs/imageprocessing/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1235, training_loss=0.5582856645468276, metrics={'train_runtime': 249.0352, 'train_samples_per_second': 158.532, 'train_steps_per_second': 4.959, 'total_flos': 993088706037120.0, 'train_loss': 0.5582856645468276, 'epoch': 5.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNwSSnFle97Z"
   },
   "source": [
    "학습이 완료되었다면, Trainer의 `evaluate` 메서드를 이용해 `dev` 스플릿에서의 최종 loss를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "VdNyUEOFfIDC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piai/anaconda3/envs/imageprocessing/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9004914164543152,\n",
       " 'eval_accuracy': 0.6602972399150743,\n",
       " 'eval_runtime': 1.1866,\n",
       " 'eval_samples_per_second': 396.928,\n",
       " 'eval_steps_per_second': 12.641,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUvrB0xUfIvv"
   },
   "source": [
    "만족할 만한 결과가 나오셨나요? 해당 결과를 kaggle에 업로드 하실려면, `dev` 스플릿의 결과가 아닌 `test` 스플릿의 결과가 필요합니다.\n",
    "\n",
    "이를 위해 `test` 스플릿에서 추론 결과를 얻고, `test_results`에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "37k4WsUihopr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 61/61 [00:01<00:00, 46.77it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "test_results = []\n",
    "\n",
    "for example_idx in tqdm(range(0, len(test_dataset), batch_size)):\n",
    "    features = test_dataset[example_idx:example_idx + batch_size if example_idx + batch_size < len(test_dataset) else len(test_dataset)]\n",
    "    batch_size = len(features['input_ids'])\n",
    "\n",
    "    # 데이터의 배치 처리가 가능하게끔 padding을 진행합니다.\n",
    "    input_ids_batch = []\n",
    "    attention_mask_batch = []\n",
    "    max_input_ids_len = max([len(feature) for feature in features['input_ids']])\n",
    "    for input_ids, attention_mask in zip(features['input_ids'], features['attention_mask']):\n",
    "        if len(input_ids) < max_input_ids_len:\n",
    "            input_ids += [tokenizer.pad_token_id] * (max_input_ids_len - len(input_ids))\n",
    "            attention_mask += [0] * (max_input_ids_len - len(attention_mask))\n",
    "        input_ids_batch.append(input_ids)\n",
    "        attention_mask_batch.append(attention_mask)\n",
    "    features_batch = {'input_ids': torch.tensor(input_ids_batch).to('cuda'),\n",
    "                      'attention_mask': torch.tensor(attention_mask_batch).to('cuda')}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**features_batch)\n",
    "        preds = model_output.logits.argmax(dim=-1)\n",
    "        preds = preds.squeeze().tolist()\n",
    "\n",
    "    for comment, pred in zip(features['comments'], preds):\n",
    "        test_results.append({'comments': comment, 'label': int(pred)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mGCbPLBrl_vD"
   },
   "source": [
    "모두 추론했다면, `test_result`에 저장된 결과를 csv 파일로 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "vwYRO15Dkf2G"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('./submission.csv', 'w', newline='') as f:\n",
    "    fieldnames = ['comments', 'label']\n",
    "    w = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    w.writeheader()\n",
    "    w.writerows(test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ew1rNVuIwT8z"
   },
   "source": [
    "파일이 정확한 포맷으로 저장됬는지 확인해봅시다.\n",
    "\n",
    "\n",
    "```\n",
    "comments,label\n",
    "(댓글 내용 1),(추론 결과 숫자)\n",
    "(댓글 내용 2),(추론 결과 숫자)\n",
    "...\n",
    "```\n",
    "의 형태로 저장되었으면 올바르게 저장된 것입니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "VG00U_Fhunq9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comments,label\n",
      "ㅋㅋㅋㅋ 그래도 조아해주는 팬들 많아서 좋겠다 ㅠㅠ 니들은 온유가 안만져줌 ㅠㅠ,1\n",
      "둘다 넘 좋다~행복하세요,0\n",
      "근데 만원이하는 현금결제만 하라고 써놓은집 우리나라에 엄청 많은데,0\n",
      "원곡생각하나도 안나고 러블리즈 신곡나온줄!!! 너무 예쁘게 잘봤어요,0\n",
      "장현승 얘도 참 이젠 짠하다...,1\n",
      "신선하게 웃긴다ㅋㅋㅋ역시 동엽신~~!! 장소연님은 진짜 조선족인가 착각할정도로 말투가 리얼하네요,0\n",
      "누군데 얘네?,1\n",
      "\"하자 인생들 모아다가 방송에 내보내고, 덜 하자가 교정해서 장사 풀리게 해주는 감동 스토리 백하자의 골목식당. 호텔 말고 그냥 하자 거리를 하나 열어서 거기다 하자 인생들 교화소를 만들지... 왜 저러고 살까...\",2\n",
      "진짜 라디오 스타 노래한거 보세요 홍진영은비비지도 못함,0\n"
     ]
    }
   ],
   "source": [
    "!head -n 10 submission.csv"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 1217218,
     "sourceId": 20930,
     "sourceType": "competition"
    },
    {
     "sourceId": 79900430,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
